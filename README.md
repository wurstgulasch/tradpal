# TradPal - AI Trading System

TradPal is a fully autonomous AI trading system based on a complete microservices architecture. The goal is consistent outperformance of Buy&Hold and traditional indicators through advanced ML models, ensemble methods, and risk management.

## ï¿½ October 2025 Highlights
- Reinforcement Learning service integration suite restored with an async-safe `httpx` test client and event-publishing mocks.
- Market Regime Detection integration tests rewritten to match the current FastAPI contract and run end-to-end in CI.
- Core EMA implementation now guarantees the first `period-1` slots are `NaN` regardless of TA-Lib availability, keeping analytics consistent across environments.

## ï¿½ğŸ—ï¸ Project Structure

```
tradpal_indicator/
â”œâ”€â”€ services/                    # Microservices Architecture
â”‚   â”œâ”€â”€ core/                    # Core calculations & Memory optimization
â”‚   â”œâ”€â”€ data_service/            # Data Management (CCXT, Kaggle, Yahoo Finance, Caching, HDF5)
â”‚   â”‚   â””â”€â”€ data_sources/        # Modular data sources (Kaggle Bitcoin Datasets, Exchanges)
â”‚   â”‚       â”œâ”€â”€ liquidation.py   # Liquidation data with fallback chain
â”‚   â”‚       â”œâ”€â”€ volatility.py    # Volatility indicators as liquidation proxy
â”‚   â”‚       â”œâ”€â”€ sentiment.py     # Sentiment analysis data source
â”‚   â”‚       â”œâ”€â”€ onchain.py       # On-chain metrics data source
â”‚   â”‚       â””â”€â”€ factory.py       # Data source factory with 8+ sources
â”‚   â”œâ”€â”€ trading_bot_live/        # Live-Trading-Engine with AI models
â”‚   â”œâ”€â”€ backtesting_service/     # Historical simulation
â”‚   â”œâ”€â”€ discovery_service/       # ML parameter optimization
â”‚   â”œâ”€â”€ risk_service/            # Risk management & position sizing
â”‚   â”œâ”€â”€ notification_service/    # Alerts (Telegram, Discord, Email)
â”‚   â”œâ”€â”€ mlops_service/           # ML experiment tracking
â”‚   â”œâ”€â”€ security_service/        # Zero-trust authentication
â”‚   â”œâ”€â”€ event_system/            # Event-Driven Architecture (Redis Streams)
â”‚   â””â”€â”€ web_ui/                  # Streamlit/Plotly dashboard
â”œâ”€â”€ config/                      # Central configuration
â”‚   â”œâ”€â”€ settings.py              # Main configuration
â”‚   â”œâ”€â”€ .env                     # Environment variables
â”‚   â”œâ”€â”€ .env.example             # Example configuration
â”‚   â”œâ”€â”€ .env.light               # Light profile (without AI/ML)
â”‚   â””â”€â”€ .env.heavy               # Heavy profile (full features)
â”œâ”€â”€ data/                        # Data directories
â”‚   â”œâ”€â”€ cache/                   # Cache files
â”‚   â”œâ”€â”€ logs/                    # Log files
â”‚   â””â”€â”€ output/                  # Output files (backtests, reports)
â”œâ”€â”€ infrastructure/              # Infrastructure & deployment
â”‚   â”œâ”€â”€ deployment/              # AWS, Kubernetes configurations
â”‚   â””â”€â”€ monitoring/              # Prometheus, Grafana setups
â”œâ”€â”€ tests/                       # Test suite (organized by best practices)
â”‚   â”œâ”€â”€ unit/                    # Unit tests
â”‚   â”œâ”€â”€ integration/             # Integration tests
â”‚   â””â”€â”€ services/                # Service-specific tests
â”œâ”€â”€ scripts/                     # Utility scripts for training/demos
â”œâ”€â”€ examples/                    # Jupyter notebooks and demos
â”œâ”€â”€ integrations/                # External integrations
â”œâ”€â”€ docs/                        # Documentation
â”œâ”€â”€ main.py                      # Hybrid orchestrator with service clients
â””â”€â”€ pyproject.toml               # Python project configuration
```

## ğŸš€ Quick Start for Developers

### New Docker-based Development Environment (Recommended)
```bash
# One-time setup
make setup

# Start services
make dev-up

# Open Web UI (optional)
make dev-ui
```

**Available Services:**
- ğŸ“Š Data Service: http://localhost:8001
- ğŸ“ˆ Backtesting Service: http://localhost:8002
- ğŸ¨ Web UI: http://localhost:8501
- ğŸš€ API Gateway: http://localhost:8000
- ğŸ“¡ Event Service: http://localhost:8011
- ğŸ“Š Monitoring: http://localhost:9090 (Prometheus), http://localhost:3000 (Grafana)

**Useful Commands:**
```bash
make test          # Run tests
make backtest      # Run backtest
make quality-check # Check code quality
make help          # Show all commands
```

ğŸ“– **[Detailed Guide](DEVELOPMENT.md)**

### Traditional Setup

### Prerequisites
- Python 3.10+
- Conda/Miniconda
- Git

### Installation

1. **Clone repository:**
   ```bash
   git clone https://github.com/wurstgulasch/tradpal.git
   cd tradpal_indicator
   ```

2. **Set up environment:**
   ```bash
   conda env create -f environment.yml
   conda activate tradpal-env
   ```

3. **Configuration:**
   ```bash
   cp config/.env.example config/.env
   # Edit .env file
   ```

4. **Run tests:**
   ```bash
   pytest tests/
   ```

### Usage

```bash
# Live trading with light profile (without AI)
python main.py --profile light --mode live

# Backtest with all features
python main.py --profile heavy --mode backtest --start-date 2024-01-01

# Performance benchmark
python scripts/performance_benchmark.py
```

## ğŸ§ª Test Organization

The test suite follows best practices for microservices:

- **Unit Tests** (`tests/unit/`): Isolated component tests
- **Integration Tests** (`tests/integration/`): Service interactions
- **Service Tests** (`tests/services/`): Service-specific tests

```bash
# All tests
pytest

# Unit tests only
pytest tests/unit/

# Service-specific tests
pytest tests/services/core/

# Integration focus areas
pytest tests/integration/test_market_regime_service.py
pytest tests/integration/test_reinforcement_learning_service.py
```

## ğŸ“Š Performance & Benchmarks

Current benchmarks show significant improvements:

- **Memory Optimization**: 10.25x faster than traditional methods, constant memory usage (~85 MB)
- **GPU Acceleration**: 3-12x faster training and inference depending on model type
- **Parallel Processing**: 4-8x faster on multi-core systems
- **Intelligent Caching**: 10-100x faster for repeated operations
- **Vectorization**: 5-15x faster indicator calculations
- **Test Coverage**: 100% for implemented features (490 tests passing)
- **Data Sources**: Modular architecture with Kaggle Bitcoin Datasets, Yahoo Finance, CCXT for improved backtesting

Detailed benchmarks: [docs/PERFORMANCE_ENHANCEMENTS.md](docs/PERFORMANCE_ENHANCEMENTS.md)

## ğŸ”Œ Data Sources Features

TradPal offers a modular data sources architecture for optimal backtesting results:

### Available Data Sources
- **Kaggle Bitcoin Datasets**: High-quality historical Bitcoin data with minute resolution
- **Yahoo Finance**: Stocks, ETFs and cryptocurrencies
- **CCXT Integration**: 100+ crypto exchanges for live data
- **Alternative Data Sources**: Sentiment analysis, on-chain metrics, volatility indicators

### Advanced Fallback System
When primary liquidation data is unavailable (API authentication issues), the system automatically falls back to alternative data sources:

```python
from services.data_service.data_sources.factory import DataSourceFactory

# Automatic fallback chain: Liquidation â†’ Volatility â†’ Sentiment â†’ On-Chain â†’ Open Interest
liquidation_source = DataSourceFactory.create_data_source('liquidation')
data = liquidation_source.fetch_recent_data('BTC/USDT', '1h', limit=100)

# Data will contain either real liquidation data or proxy data from alternative sources
# with 'data_source' field indicating which fallback was used
```

### Alternative Data Sources

#### Sentiment Analysis (`sentiment.py`)
- **Fear & Greed Index**: Real-time market sentiment from Alternative.me
- **Social Sentiment**: Simulated social media sentiment analysis
- **News Sentiment**: Market news sentiment indicators
- **Market Sentiment**: Overall market psychology proxy

#### On-Chain Metrics (`onchain.py`)
- **Active Addresses**: Daily active blockchain addresses
- **Transaction Volume**: On-chain transaction volumes
- **Hash Rate**: Network mining difficulty proxy
- **Exchange Flows**: Net capital flows to/from exchanges

#### Volatility Indicators (`volatility.py`)
- **Open Interest**: Futures market positioning
- **24h Volume**: Trading volume analysis
- **Funding Rates**: Perpetual futures funding rates
- **Order Book**: Market depth and bid-ask spreads
- **Recent Trades**: Trade flow analysis and momentum

### Data Quality & Validation
- Automatic OHLC validation
- NaN value handling
- Consistent data formats
- Chunked processing for large datasets

## ğŸ›ï¸ Architecture Principles

- **Microservices-First**: Every new functionality as a separate service
- **Event-Driven**: Redis Streams for real-time service communication
- **API Gateway**: Centralized service routing, authentication, and load balancing
- **Zero-Trust-Security**: mTLS, OAuth/JWT, secrets management
- **Observability**: Prometheus/Grafana monitoring, distributed tracing, metrics, logs
- **Resilience**: Circuit breaker, retry patterns, health checks, chaos engineering

## ğŸ”§ Development

### Adding New Features
1. Create service in `services/`
2. Add tests in `tests/services/`
3. Update documentation
4. Extend CI/CD pipeline

### Code Quality
- **Type Safety**: Complete type hints
- **Testing**: >90% coverage, integration tests
- **Linting**: flake8, mypy
- **Formatting**: black, isort

## ğŸ“ˆ Roadmap 2025

âœ… **Completed:**
- Event-Driven Architecture with Redis Streams
- API Gateway with service discovery and load balancing
- Centralized monitoring with Prometheus/Grafana
- Circuit breaker and health check resilience patterns

ğŸ”„ **In Progress:**
1. **AI Outperformance**: ML models that consistently outperform benchmarks
2. **Service Optimization**: Performance, scalability, reliability
3. **Advanced Features**: Reinforcement learning, market regime detection, alternative data
4. **Data Sources Expansion**: Additional datasets and real-time feeds for improved backtesting
5. **Enterprise Readiness**: Security, monitoring, deployment automation

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Write tests
4. Commit changes (`git commit -m 'Add some AmazingFeature'`)
5. Push to branch (`git push origin feature/AmazingFeature`)
6. Create Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/wurstgulasch/tradpal/issues)
- **Documentation**: [docs/](docs/)
- **Examples**: [examples/](examples/)

---

**TradPal v3.0.1** - *Last updated: October 2025*
