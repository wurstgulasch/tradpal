# TradPal - AI Trading System

TradPal is a fully autonomous AI trading system based on a complete microservices architecture. The goal is consistent outperformance of Buy&Hold and traditional indicators through advanced ML models, ensemble methods, and risk management.

## ğŸ¯ October 2025 Highlights
- **98 Test Files**: Comprehensive test coverage with organized test structure (unit/integration/services/e2e)
- **Service Consolidation**: Partial consolidation of 25+ services into unified trading, data, and backtesting services
- **Advanced ML Integration**: ML-enhanced signal generation with ensemble methods and risk management
- **Modular Data Sources**: Kaggle Bitcoin Datasets, Yahoo Finance, CCXT integration for optimal backtesting
- **Centralized Test Suite**: Organized test structure with conftest.py, fixtures, and comprehensive coverage

## ğŸ—ï¸ Project Structure

```
tradpal/
â”œâ”€â”€ services/                    # Microservices Architecture (25+ services, partial consolidation)
â”‚   â”œâ”€â”€ core/                    # Core calculations & Memory optimization
â”‚   â”œâ”€â”€ data_service/            # Data Management (CCXT, Kaggle, Yahoo Finance, caching, HDF5)
â”‚   â”‚   â””â”€â”€ data_sources/        # Modular data sources (Kaggle Bitcoin Datasets, Exchanges)
â”‚   â”‚       â”œâ”€â”€ liquidation.py   # Liquidation data with fallback chain
â”‚   â”‚       â”œâ”€â”€ volatility.py    # Volatility indicators as liquidation proxy
â”‚   â”‚       â”œâ”€â”€ sentiment.py     # Sentiment analysis data source
â”‚   â”‚       â”œâ”€â”€ onchain.py       # On-chain metrics data source
â”‚   â”‚       â””â”€â”€ factory.py       # Data source factory with 8+ sources
â”‚   â”œâ”€â”€ trading_service/         # Consolidated AI-powered trading service
â”‚   â”‚   â”œâ”€â”€ orchestrator.py      # Main trading orchestrator
â”‚   â”‚   â”œâ”€â”€ execution/           # Order execution
â”‚   â”‚   â”œâ”€â”€ risk_management/     # Risk management
â”‚   â”‚   â”œâ”€â”€ reinforcement_learning/ # RL agents
â”‚   â”‚   â”œâ”€â”€ market_regime/       # Market regime detection
â”‚   â”‚   â””â”€â”€ monitoring/          # Trading monitoring
â”‚   â”œâ”€â”€ backtesting_service/     # Historical simulation and ML training
â”‚   â”œâ”€â”€ discovery_service/       # ML parameter optimization
â”‚   â”œâ”€â”€ risk_service/            # Risk management and position sizing
â”‚   â”œâ”€â”€ notification_service/    # Alerts (Telegram, Discord, Email)
â”‚   â”œâ”€â”€ mlops_service/           # ML experiment tracking and model management
â”‚   â”œâ”€â”€ security_service/        # Zero-trust authentication
â”‚   â”œâ”€â”€ event_system/            # Event-Driven Architecture (Redis Streams)
â”‚   â”œâ”€â”€ api_gateway/             # Centralized service routing and authentication
â”‚   â””â”€â”€ [20+ additional services]/ # Individual microservices (pending consolidation)
â”œâ”€â”€ config/                      # Central configuration
â”‚   â”œâ”€â”€ settings.py              # Main configuration (imports from modules)
â”‚   â”œâ”€â”€ core_settings.py         # Core trading and risk management
â”‚   â”œâ”€â”€ ml_settings.py           # Machine learning and AI configurations
â”‚   â”œâ”€â”€ service_settings.py      # Microservices and data mesh settings
â”‚   â”œâ”€â”€ security_settings.py     # Security and authentication settings
â”‚   â”œâ”€â”€ performance_settings.py  # Performance optimization settings
â”‚   â”œâ”€â”€ .env                     # Environment variables
â”‚   â”œâ”€â”€ .env.example             # Example configuration
â”‚   â”œâ”€â”€ .env.light               # Light profile (without AI/ML)
â”‚   â””â”€â”€ .env.heavy               # Heavy profile (full features)
â”œâ”€â”€ tests/                       # Centralized test suite (98 test files)
â”‚   â”œâ”€â”€ conftest.py              # Central test configuration and fixtures
â”‚   â”œâ”€â”€ unit/                    # Unit tests (25+ files)
â”‚   â”œâ”€â”€ integration/             # Integration tests (13+ files)
â”‚   â”œâ”€â”€ services/                # Service-specific tests
â”‚   â”œâ”€â”€ e2e/                     # End-to-end tests
â”‚   â”œâ”€â”€ config/                  # Configuration tests
â”‚   â””â”€â”€ integrations/            # Integration setup tests
â”œâ”€â”€ scripts/                     # Utility scripts for training/demos
â”œâ”€â”€ examples/                    # Jupyter notebooks and demos
â”œâ”€â”€ integrations/                # External integrations
â”œâ”€â”€ docs/                        # Documentation
â”œâ”€â”€ main.py                      # Hybrid orchestrator with service clients
â””â”€â”€ pyproject.toml               # Python project configuration
```

## ğŸš€ Quick Start for Developers

### New Docker-based Development Environment (Recommended)
```bash
# One-time setup
make setup

# Start services
make dev-up

# Open Web UI (optional)
make dev-ui
```

**Available Services:**
- ğŸ“Š Data Service: http://localhost:8001
- ğŸ“ˆ Backtesting Service: http://localhost:8002
- ğŸ¨ Web UI: http://localhost:8501
- ğŸš€ API Gateway: http://localhost:8000
- ğŸ“¡ Event Service: http://localhost:8011
- ğŸ“Š Monitoring: http://localhost:9090 (Prometheus), http://localhost:3000 (Grafana)

**Useful Commands:**
```bash
make test          # Run tests
make backtest      # Run backtest
make quality-check # Check code quality
make help          # Show all commands
```

ğŸ“– **[Detailed Guide](DEVELOPMENT.md)**

### Traditional Setup

### Prerequisites
- Python 3.10+
- Conda/Miniconda
- Git

### Installation

1. **Clone repository:**
   ```bash
   git clone https://github.com/wurstgulasch/tradpal.git
   cd tradpal_indicator
   ```

2. **Set up environment:**
   ```bash
   conda env create -f environment.yml
   conda activate tradpal-env
   ```

3. **Configuration:**
   ```bash
   cp config/.env.example config/.env
   # Edit .env file
   ```

4. **Run tests:**
   ```bash
   pytest tests/
   ```

### Usage

```bash
# Live trading with light profile (without AI)
python main.py --profile light --mode live

# Backtest with all features
python main.py --profile heavy --mode backtest --start-date 2024-01-01

# Performance benchmark
python scripts/performance_benchmark.py
```

## ğŸ§ª Test Organization

The test suite follows best practices for microservices:

- **Unit Tests** (`tests/unit/`): Isolated component tests
- **Integration Tests** (`tests/integration/`): Service interactions
- **Service Tests** (`tests/services/`): Service-specific tests

```bash
# All tests
pytest

# Unit tests only
pytest tests/unit/

# Service-specific tests
pytest tests/services/core/

# Integration focus areas
pytest tests/integration/test_market_regime_service.py
pytest tests/integration/test_reinforcement_learning_service.py
```

## ğŸ“Š Performance & Benchmarks

Current benchmarks show significant improvements:

- **Memory Optimization**: 10.25x faster than traditional methods, constant memory usage (~85 MB)
- **GPU Acceleration**: 3-12x faster training and inference depending on model type
- **Parallel Processing**: 4-8x faster on multi-core systems
- **Intelligent Caching**: 10-100x faster for repeated operations
- **Vectorization**: 5-15x faster indicator calculations
- **Test Coverage**: 100% for implemented features (537 tests passing)
- **Data Sources**: Modular architecture with Kaggle Bitcoin Datasets, Yahoo Finance, CCXT for improved backtesting

Detailed benchmarks: [docs/PERFORMANCE_ENHANCEMENTS.md](docs/PERFORMANCE_ENHANCEMENTS.md)

## ğŸ”Œ Data Sources Features

TradPal offers a modular data sources architecture for optimal backtesting results:

### Available Data Sources
- **Kaggle Bitcoin Datasets**: High-quality historical Bitcoin data with minute resolution
- **Yahoo Finance**: Stocks, ETFs and cryptocurrencies
- **CCXT Integration**: 100+ crypto exchanges for live data
- **Alternative Data Sources**: Sentiment analysis, on-chain metrics, volatility indicators

### Advanced Fallback System
When primary liquidation data is unavailable (API authentication issues), the system automatically falls back to alternative data sources:

```python
from services.data_service.data_sources.factory import DataSourceFactory

# Automatic fallback chain: Liquidation â†’ Volatility â†’ Sentiment â†’ On-Chain â†’ Open Interest
liquidation_source = DataSourceFactory.create_data_source('liquidation')
data = liquidation_source.fetch_recent_data('BTC/USDT', '1h', limit=100)

# Data will contain either real liquidation data or proxy data from alternative sources
# with 'data_source' field indicating which fallback was used
```

### Alternative Data Sources

#### Sentiment Analysis (`sentiment.py`)
- **Fear & Greed Index**: Real-time market sentiment from Alternative.me
- **Social Sentiment**: Simulated social media sentiment analysis
- **News Sentiment**: Market news sentiment indicators
- **Market Sentiment**: Overall market psychology proxy

#### On-Chain Metrics (`onchain.py`)
- **Active Addresses**: Daily active blockchain addresses
- **Transaction Volume**: On-chain transaction volumes
- **Hash Rate**: Network mining difficulty proxy
- **Exchange Flows**: Net capital flows to/from exchanges

#### Volatility Indicators (`volatility.py`)
- **Open Interest**: Futures market positioning
- **24h Volume**: Trading volume analysis
- **Funding Rates**: Perpetual futures funding rates
- **Order Book**: Market depth and bid-ask spreads
- **Recent Trades**: Trade flow analysis and momentum

### Data Quality & Validation
- Automatic OHLC validation
- NaN value handling
- Consistent data formats
- Chunked processing for large datasets

## ğŸ›ï¸ Architecture Principles

- **Microservices-First**: Every new functionality as a separate service
- **Event-Driven**: Redis Streams for real-time service communication
- **API Gateway**: Centralized service routing, authentication, and load balancing
- **Zero-Trust-Security**: mTLS, OAuth/JWT, secrets management
- **Observability**: Prometheus/Grafana monitoring, distributed tracing, metrics, logs
- **Resilience**: Circuit breaker, retry patterns, health checks, chaos engineering

## ğŸ“¦ Dependency Management

TradPal uses a sophisticated dependency management system designed for microservice independence:

### Central Dependency Catalog
- **Single Source of Truth**: `dependency_catalog.txt` defines approved package versions
- **Version Consistency**: All services use exact versions from the catalog
- **Automated Validation**: Scripts ensure compliance across all services

### Service-Specific Requirements
Each service in `services/` has its own `requirements.txt` with:
- Only packages the service actually needs
- Exact pinned versions from the catalog
- Independent deployment capability

### Management Tools
```bash
# Validate all service dependencies
python scripts/manage_dependencies.py validate

# List all approved dependencies
python scripts/manage_dependencies.py list

# Update package version across all services
python scripts/manage_dependencies.py update <package> <version>
```

### Benefits
- **True Microservice Independence**: Services can be deployed without shared dependencies
- **Version Drift Prevention**: Automated validation prevents conflicts
- **Simplified Updates**: Single command updates versions across all services
- **Clean Architecture**: No dependency conflicts between services

## ğŸ”§ Development

### Adding New Features
1. Create service in `services/`
2. Add tests in `tests/services/`
3. Update documentation
4. Extend CI/CD pipeline

### Code Quality
- **Type Safety**: Complete type hints
- **Testing**: >90% coverage, integration tests
- **Linting**: flake8, mypy
- **Formatting**: black, isort

## ğŸ“ˆ Roadmap 2025

âœ… **Completed:**
- Event-Driven Architecture with Redis Streams
- API Gateway with service discovery and load balancing
- Centralized monitoring with Prometheus/Grafana
- Circuit breaker and health check resilience patterns

ğŸ”„ **In Progress:**
1. **AI Outperformance**: ML models that consistently outperform benchmarks
2. **Service Optimization**: Performance, scalability, reliability
3. **Advanced Features**: Reinforcement learning, market regime detection, alternative data
4. **Data Sources Expansion**: Additional datasets and real-time feeds for improved backtesting
5. **Enterprise Readiness**: Security, monitoring, deployment automation

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Write tests
4. Commit changes (`git commit -m 'Add some AmazingFeature'`)
5. Push to branch (`git push origin feature/AmazingFeature`)
6. Create Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/wurstgulasch/tradpal/issues)
- **Documentation**: [docs/](docs/)
- **Examples**: [examples/](examples/)

---

**TradPal v2.5.1** - *Last updated: October 21, 2025*
