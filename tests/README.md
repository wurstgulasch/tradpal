# TradPal Indicator - Test Suite

## ðŸ“ Test Structure

The test suite mirrors the project structure and is organized as follows:

```
tests/
â”œâ”€â”€ config/                    # Configuration tests
â”‚   â””â”€â”€ test_config.py
â”œâ”€â”€ src/                       # Core module tests
â”‚   â”œâ”€â”€ test_data_fetcher.py
â”‚   â”œâ”€â”€ test_indicators.py
â”‚   â”œâ”€â”€ test_output.py
â”‚   â””â”€â”€ test_backtester.py
â”œâ”€â”€ integrations/              # Integration tests
â”‚   â””â”€â”€ test_integrations.py
â”œâ”€â”€ scripts/                   # Script tests
â”‚   â””â”€â”€ test_scripts.py
â”œâ”€â”€ test_error_handling.py     # Comprehensive error handling tests
â”œâ”€â”€ test_edge_cases.py         # Edge cases and special scenarios
â”œâ”€â”€ test_performance.py        # Performance and load tests
â””â”€â”€ __init__.py
```

## ðŸ§ª Test Categories

### Unit Tests
- **data_fetcher**: Data retrieval and exchange validation
- **indicators**: Technical indicators (EMA, RSI, BB, ATR, ADX)
- **output**: JSON formatting and file operations
- **backtester**: Historical backtesting functionality
- **config**: Configuration parameters and validation

### Integration Tests
- **integrations**: Telegram/Email notifications
- **scripts**: CLI tools and automation scripts

### Special Tests
- **error_handling**: Comprehensive error handling for all modules
- **edge_cases**: Edge cases and unusual scenarios
- **performance**: Performance benchmarks and load tests

## ðŸš€ Running Tests

### All Tests
```bash
python run_tests.py
```

### With Verbose Output
```bash
python run_tests.py --verbose
```

### With Coverage Report
```bash
python run_tests.py --coverage
```

### Specific Test Files
```bash
python run_tests.py --test-files tests/src/test_data_fetcher.py tests/src/test_indicators.py
```

### Individual Test Modules
```bash
# Only Data Fetcher Tests
python -m pytest tests/src/test_data_fetcher.py -v

# Only Performance Tests
python -m pytest tests/test_performance.py -v
```

## ðŸ“Š Test Coverage

The test suite provides comprehensive coverage for:

- âœ… **120+ individual tests**
- âœ… Unit tests for all core functions
- âœ… Integration tests for external services
- âœ… Error handling for all error scenarios
- âœ… Edge cases for boundary conditions
- âœ… Performance benchmarks
- âœ… Mock-based tests for APIs

## ðŸ› ï¸ Test Framework

- **pytest**: Modern test framework with extensive features
- **unittest.mock**: Mocking for external APIs and services
- **pandas/numpy**: Data processing in tests
- **tempfile**: Temporary files for I/O tests

## ðŸ“ˆ Quality Metrics

- **Zero Failures**: All tests must pass
- **High Coverage**: >90% code coverage targeted
- **Fast Execution**: Tests run in <30 seconds
- **Reliable**: Deterministic, non-flaky tests

## ðŸ”§ Test Development

### Adding New Tests:
1. Create test file in appropriate subdirectory
2. Follow pytest conventions (test_*.py)
3. Include comprehensive docstrings and comments
4. Mock external dependencies

### Test Naming Conventions:
- `test_function_name()`: Unit tests
- `test_feature_scenario()`: Integration tests
- `TestClassName`: Test classes
- `test_method_name()`: Methods in test classes

## ðŸ“‹ CI/CD Integration

The tests are optimized for automatic execution in CI/CD pipelines:

- Parallel execution possible
- JUnit/XML output for reporting
- Coverage reports for quality metrics
- Fail-fast on critical errors

---

*Automatically generated for TradPal Indicator v2.0*